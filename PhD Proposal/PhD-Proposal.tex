\documentclass[useAMS,usenatbib,referee]{biom}
%\documentclass[useAMS,usenatbib,referee]{biom}
%
%
%  Papers submitted to Biometrics should ALWAYS be prepared
%  using the referee option!!!!
%
%
% If your system does not have the AMS fonts version 2.0 installed, then
% remove the useAMS option.
%
% useAMS allows you to obtain upright Greek characters.
% e.g. \umu, \upi etc.  See the section on "Upright Greek characters" in
% this guide for further information.
%
% If you are using AMS 2.0 fonts, bold math letters/symbols are available
% at a larger range of sizes for NFSS release 1 and 2 (using \boldmath or
% preferably \bmath).
%
% The usenatbib command allows the use of Patrick Daly's natbib package for
% cross-referencing.
%
% If you wish to typeset the paper in Times font (if you do not have the
% PostScript Type 1 Computer Modern fonts you will need to do this to get
% smoother fonts in a PDF file) then uncomment the next line
% \usepackage{Times}
%%%%% AUTHORS - PLACE YOUR OWN MACROS HERE %%%%%

\usepackage[figuresright]{rotating}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage[hyphens]{url} % not crucial - just used below for the URL
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{booktabs}
%% \raggedbottom % To avoid glue in typesetteing, sbs>>

% Pandoc syntax highlighting
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}

% tightlist command for lists without linebreak
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\setcounter{footnote}{2}

\title[]{Extension of People-Like-Me Methods Penalization, Prediction,
and Beyond}

\author{ Randy
Jin \email{\href{mailto:xin.2.jin@cuanschutz.edu}{\nolinkurl{xin.2.jin@cuanschutz.edu}}} \\ Department
of Biostatistics and Bioinformatics, University of Colorado Anschutz
Medical Campus  \and
		 Elizabeth
Juarez-Colunga \email{\href{mailto:elizabeth.juarez-colunga@cuanschutz.edu}{\nolinkurl{elizabeth.juarez-colunga@cuanschutz.edu}}} \\ Department
of Biostatistics and Bioinformatics, University of Colorado Anschutz
Medical Campus 
	   }


\begin{document}


\date{{\it Received Jan} 2024}

\pagerange{\pageref{firstpage}--\pageref{lastpage}} \pubyear{2024}

\volume{0}
\artmonth{January}
\doi{0000-0000-0000}

%  This label and the label ``lastpage'' are used by the \pagerange
%  command above to give the page range for the article

\label{firstpage}

%  pub the summary here

\begin{abstract}
The text of your summary. Should not exceed 225 words.
\end{abstract}

%
%  Please place your key words in alphabetical order, separated
%  by semicolons, with the first letter of the first word capitalized,
%  and a period at the end of the list.
%

\begin{keywords}
inversed-distance weightcurve matchingpredictive interval.
\end{keywords}

\maketitle

\hypertarget{intro}{%
\section{1. Introduction}\label{intro}}

Your text comes here. Separate text sections with

\hypertarget{s:methods}{%
\section{2. Methods}\label{s:methods}}

Text with citations by \citet{heagerty2000time},
\citep{pepe2003statistical}.

The prediction horizon extends to the

\hypertarget{ss:pcr}{%
\subsection{2.2 The predictive coverage interval}\label{ss:pcr}}

The problem for the predictive interval with gamlss model:

Q1. The predictive interval is symmetric, but in fact is a not a
requirement for the prediction interval based on our selected matches.
The systematic bias introduced by the asymmetric distribution for the
matches observations; The systematic bias introduced by the density of
the given time points.

(using weights can be a solution for the systematic bias, but we need to
be careful about the weights we used.) for example, imagine the tallest
person in the study, that all the other people served as matches would
be shorter than this target. The prediction based on such matches would
be still underestimated. However, we can use the weights to adjust the
prediction based on the distance. which means the prediction will be
more close too potentially the second tallest individual (the tallest
one in the training set). Even though, we cannot accurately predict for
the target, but we can extract certain information which provided by
what we know, other than nothing. But we still need to find a way to
quantify such limitation.

\textbf{This means for the distance calculation, we need to identify the
targets with certain matching patterns . What would those patterns be?
Does them need to be time point-wised, or individual level?}

For this problem we propose a new method to calculate the prediction
interval for the response variable. Do not based on the gamlss
prediction but based on a new method to calculate the prediction
interval for the response variable. such as the quantile regression
methods or other interval estimation methods.

A calibration for the internal validation? We split the training set
again into a training set and a validation set. We use the training set
to fit the model and the validation set to calibrate interval we get. We
can use the residuals from validation set to calibrate the prediction
interval for the response variable. Should this be more accurate than
the prediction interval based on the training set solely?

Use the weights from the distance, however we can only weight on the
individual level. the weights from the time points to calculate the
prediction interval for the response variable.

Q2. The prediction interval is not a point-wise prediction interval, but
a trajectory-wise prediction interval. What does it mean for the
point-wise prediction interval and the trajectory-wise prediction
interval?

How to quantify and avoid systematic bias in the predictions?

The point-wise, the trajectory-wise, and the population level prediction
interval. we probably need to do a simulation test to see how things
going. and Say for example our methods have the same over-estimated
coverage rate for the prediction interval, just the same as our
simulated results.

\begin{itemize}
\item
  the point-wise coverage probability, which is described as the
  probability that the interval contains the true value of the response
  at a given time point. let's say for the 10th day, what is the
  coverage rate for the prediction interval for the response variable.
  This is similar to the coverage for the parameters, which is the most
  commonly used one. The problem rises because we do not have balanced
  data. we cannot find a same time point for everybody.
\item
  the segmented coverage probability of intervals
\end{itemize}

piece-wised time segments for coverage rate of the prediction interval.
for example, for 10 - 20 days, what is the coverage rate for the
prediction interval for the response variable.

But still given each individual or for the population level. what if for
certain individual there is no observation in this interval at all.

\begin{itemize}
\tightlist
\item
  the trajectory-wise prediction interval
\end{itemize}

We can calculate the prediction interval for each trajectory first. The
data will be grouped in each individual trajectory, so a proportion of
the coverage is calculated for that individual. Then we can calculate
the average coverage rate for the whole population.

\begin{itemize}
\tightlist
\item
  the population level prediction interval
\end{itemize}

This is the methods we currently used, we calculated the predictive
interval for each observation whether it is contained in its own
predictive interval. Then we take the average of the predictive coverage
rate for each observation in each .

as required \citep{hoerl1970ridge, zou2005regularization}. Don't forget
to give each section and subsection a unique label (see Sect.
\ref{sec:1}).

\hypertarget{paragraph-headings}{%
\paragraph{Paragraph headings}\label{paragraph-headings}}

Use paragraph headings as needed.

\hypertarget{equations}{%
\subsection{3. Equations}\label{equations}}

Here is an equation:

\[ f_{X}(x) = \left(\frac{\alpha}{\beta}\right)\left(\frac{x}{\beta}\right)^{\alpha-1}e^{-\left(\frac{x}{\beta}\right)^{\alpha}}; \alpha,\beta,x > 0 \]

Here is another: \begin{align}
a^2+b^2=c^2
\end{align}

Inline equations: \(\sum_{i = 2}^\infty\{\alpha_i^\beta\}\)

\hypertarget{s:fig}{%
\section{Figures and tables}\label{s:fig}}

\hypertarget{figures-coming-from-r}{%
\subsection{Figures coming from R}\label{figures-coming-from-r}}

\hypertarget{normal-figure-embedded-in-text}{%
\paragraph{Normal figure embedded in
text}\label{normal-figure-embedded-in-text}}

\begin{verbatim}
## Warning in plot.formula(runif(25) ~ runif(25)): the formula 'runif(25) ~
## runif(25)' is treated as 'runif(25) ~ 1'
\end{verbatim}

\begin{figure}
\centering
\includegraphics{PhD-Proposal_files/figure-latex/fig2-1.pdf}
\caption{Output from \texttt{pdf()}}
\end{figure}

\clearpage

\hypertarget{tables-coming-from-r}{%
\subsection{Tables coming from R}\label{tables-coming-from-r}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(xtable}\SpecialCharTok{::}\FunctionTok{xtable}\NormalTok{(}\FunctionTok{head}\NormalTok{(mtcars)[,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{], }
\AttributeTok{caption =} \StringTok{"Caption centered under table"}\NormalTok{, }\AttributeTok{label =} \StringTok{"tab1"}\NormalTok{), }
\AttributeTok{comment =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{timestamp =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{caption.placement =} \StringTok{"top"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[ht]
\centering
\caption{Caption centered under table} 
\label{tab1}
\begin{tabular}{rrrrr}
  \hline
 & mpg & cyl & disp & hp \\ 
  \hline
Mazda RX4 & 21.00 & 6.00 & 160.00 & 110.00 \\ 
  Mazda RX4 Wag & 21.00 & 6.00 & 160.00 & 110.00 \\ 
  Datsun 710 & 22.80 & 4.00 & 108.00 & 93.00 \\ 
  Hornet 4 Drive & 21.40 & 6.00 & 258.00 & 110.00 \\ 
  Hornet Sportabout & 18.70 & 8.00 & 360.00 & 175.00 \\ 
  Valiant & 18.10 & 6.00 & 225.00 & 105.00 \\ 
   \hline
\end{tabular}
\end{table}

Table \ref{tab1} shows these numbers. Some of those numbers are plotted
in Figure \ref{fig2}.


\bibliographystyle{biom}
\bibliography{bibliography.bib}


\label{lastpage}


\end{document}
